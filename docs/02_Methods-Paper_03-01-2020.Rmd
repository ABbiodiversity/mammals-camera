---
title: "Monitoring the mammalian community in Alberta's boreal region with remote cameras"
subtitle: "Application of the REST model to large-scale biodiversity monitoring"
author: "Huggard et al."
date: "March 23, 2020"
output:
  word_document: default
  html_document: default
---

```{r setup, include=FALSE}

knitr::opts_chunk$set(include=TRUE, echo=TRUE, message=FALSE, warning=FALSE, eval=TRUE, cache=FALSE)



```

# Outline

1. The Alberta Biodiversity Monitoring Institute (ABMI) monitors mammal populations across the province of Alberta using remote camera traps in order to report on abundance, habitat associations, and trend. From 2013-2019, a total of 2,500 cameras were deployed in a systematic random sampling design, yielding nearly 700,000 images of 42 species of native mammals.

2. We use a modified version of the random encounter and staying time (REST) model developed by *Nakashima et al 2019*, which in turn was an extension of the random encounter model (REM) first proposed by *Rowcliffe et al 2008*. The REST model is used to estimate density based on the total time that a species spends in the camera's field of view (or, more specifically, 'detection zone'), and does not require information on home range size and movement rates. The model also does not require individual recognition. We modify the model developed by *Nakashima et al 2019* by including a procedure to estimate animal staying time from series of images taken at discrete intervals (rather than video), and the development of species, habitat, and seasonally varying models of the effective detection distance (EDD) of cameras. This latter component was developed using image data collected from a full field season (2015), rather than a laboratory. We discuss important assumtions of using this model to estimate the absolute density of a species, including the necessity that cameras survey a random (or representative) sample of the larger region and that animals are not attracted to or repelled by the cameras.

3. We report density estimates based on data collected from 2,500 cameras deployed throughout the province from 2013 to 2019 for six small- to large-size mammal species of interest (which range from relatively common to relatively rare): white-tailed deer, moose, black bear, coyote, snowshoe hare, and gray wolf. We scale up these density estimates to the Wildlife Management Unit (WMU; an important spatial unit for wildlife management in the province) and use Monte Carlo simulation to estimate confidence bounds. The expected precision of these estimates, and the ensuing implications for management, differ greatly depending on the number of cameras and the relative prevalence of the species of interest. We use additional Monte Carlo simulation to illustrate how expected precision changes with sampling effort for the focal species listed above.

4. Since 2014, aerial surveys using distance sampling methods have been used to monitor ungulate populations at the WMU level in Alberta. We compare density estimates of moose obtained from the REST model to those reported via aerial surveys, and find a significantly positive relationship. Estimates from the REST model were approximately 2-3 times higher than than their equivalent aerial estimate, highlighting a likely violation of model assumptions (e.g. moose not being attracted to the camera). However, we suggest density derived via REST can be useful as a metric of *relative* density, provided that assumptions are violated equally over time and space. We propose a preliminary approach to scale REST estimates to their aerial equivalent.

5. Finally, we outline how relative density estimates derived via REST at camera deployments can be used to form inference on the habitat preferences of species. We use a joint presence-absence/abundance-given-presence approach to model moose habitat associations in the boreal region of Alberta.

## Key Features 

- Application of the random encounter staying time (REST) model by a multi-species biodiversity monitoring program with large temporal and spatial breadth.
  + Includes proposed modifications to the original REST model in order to handle images taken at discrete intervals and methods to account for variation in effective detection distance (EDD) by species, habitat, and season. 
  
- Comparison to other, well-developed large-scale methods for animal population monitoring, i.e. aerial surveys.

- Use of REST-derived density estimates at individual camera deployment sampling points to study habitat preference.
  
```{r, cache=TRUE}

# Load packages
library(dplyr) # data manipulation
library(readr) # read in csv data
library(mgcv) # gam modeling
library(stringr)
library(purrr)
library(tidyr)
library(lubridate) # dates
library(forcats) # factors
library(ggplot2) # visualizations

# Path to data folder on ABMI Science Centre S: drive
abmisc <- "S:/github-repos-data/SC-Camera-Mammals/data/"
# Path to data folder on MB's external hardrive 
mbhd <- "D:/SC-Camera-Mammals/data/"

# Import data:
# Raw native mammal data (2013-2018):
df_native_all <- read_csv(paste0(mbhd,"base/ALL_native-mammals_09-01-2019.csv"),
                          col_types = cols(distance = col_character(),
                                           number_during_gap = col_number(),
                                           number_individuals = col_character()),
                          na = "")

# Species distance groups:
df_dist_groups <- read_csv(paste0(mbhd,"lookup/species-distance-groups.csv"))

# Vegetation and Human Footprint (HF) information for each deployment:
df_veghf_detdist <- read_csv(paste0(mbhd,"lookup/camera-soilveghf-detdist-all.csv"))

# Veg-HF groupings for detection distance models:
df_veg_lookup <- read_csv(paste0(mbhd,"lookup/veg-pole-distance.csv"))

# Lure information for all deployments:
df_cam_lure <- read_csv(paste0(mbhd,"lookup/camera-lure-info-all.csv"))

# Set analysis parameters for density estimation

# Seasonal start/end dates (julian day):
summer.start.j <- 106 # April 16
summer.end.j <- 288 # October 15

# Reconyx camera field-of-view angle:
cam_fov_ang <- 42

# Species we're interested in for this paper:
Sp <- c("White-tailed Deer", "Moose", "Black Bear", "Coyote", "Snowshoe Hare", "Gray Wolf")

# Species gap groups:
df_gap_groups <- read_csv(paste0(mbhd,"lookup/species-gap-groups.csv")) %>%
  # Name the groups for clarity
  mutate(gap_group = case_when(
    gap_group == 1 ~ "Most ungulates",
    gap_group == 2 ~ "Moose",
    gap_group == 3 ~ "Small carnivores",
    gap_group == 4 ~ "Canids cougar",
    gap_group == 5 ~ "Bears",
    gap_group == 6 ~ "Small mammals"))

# Camera operating dates/times:
df_cam_startend <- read_csv(paste0(mbhd,"lookup/camera-startend-all.csv")) %>%
  mutate(DeploymentYear = paste(deployment, year, sep ="_")) %>%
  select(DeploymentYear, deployment, year, StartTime, EndTime)

# Camera operating timeframes (wide):
time.since.2009 <- read_csv(paste0(mbhd,"processed/dave-objects/Camera operating days since 2009 Feb 2019 ALL.csv"))
time.by.day <- read_csv(paste0(mbhd, "processed/dave-objects/Camera operating days Feb 2019 ALL.csv"))
df_tbd_summary <- read_csv(paste0(mbhd,"processed/dave-objects/Summary of camera operating days Feb 2019 ALL.csv"))


```

```{r}

# Identify series'

df_series <- df_native_all %>%
  # Transform date_time_taken to POSIXct object
  mutate(date_time_taken = ymd_hms(date_time_taken)) %>%
  # Order observations
  arrange(deployment, Year, common_name, date_time_taken) %>%
  # Identify series
  mutate(series_num = 0,
         # Lagged date_time_taken
         date_time_taken_lag = lag(date_time_taken),
         # Calculate difference in time (seconds) between images
         diff_time = as.numeric(date_time_taken - date_time_taken_lag),
         # Lagged species
         common_name_lag = lag(common_name),
         # Is it a different species? (boolean)
         diff_sp = ifelse(common_name != common_name_lag, TRUE, FALSE),
         # Lagged deployment
         deployment_lag = lag(deployment),
         # Is it a different deployment? (boolean)
         diff_dep = ifelse(deployment != deployment_lag, TRUE, FALSE),
         # Identify series
         diff_series = ifelse(diff_dep == TRUE | diff_sp == TRUE | diff_time > 120,
                              1, 0),
         # Number series
         series_num = c(0, cumsum(diff_series[-1])),
         # Flag gaps that need checking later
         gap_check = ifelse(diff_dep == FALSE & diff_sp == FALSE & (diff_time <= 120 & diff_time >= 20),
                            1, 0),
         # Lagged gap class (to align with gap_check and diff_time)
         gap_class_lag = lag(gap_class)) %>%
  # Clean up species common_name
  filter(!common_name == "Falcons and allies") %>%
  filter(!common_name == "Wolves, Coyotes and Allies") %>%
  mutate(common_name = ifelse(common_name == "Foxes", "Red fox", common_name),
         common_name = ifelse(common_name == "Mule Deer", "Mule deer", common_name))

# Create dataframe of each obs we previously flagged to check gap
df_gapcheck <- df_series %>%
  filter(!is.na(gap_class_lag) & gap_check == "1") %>%
  select(common_name, gap_class_lag, diff_time) %>%
  # Create new left variable - did the animal leave the field of view?
  mutate(left = ifelse(gap_class_lag == "P", 0, 1)) %>%
  select(-gap_class_lag)

mod_gapcheck_sub <- df_gapcheck %>%
  filter(common_name %in% Sp) %>%
  group_by(common_name) %>%
  nest() %>%
  mutate(model = map(.x = data, ~ smooth.spline(x = .$diff_time, y = .$left, df = 3)),
         pred = map(.x = model, ~ predict(., type = "response", x = 20:120))) %>%
  select(common_name, pred) %>%
  unnest_wider(pred) %>%
  unnest(cols = c(x,y)) %>%
  rename(seconds = x, pred = y)

```

---

# Introduction

Accurate and reliable information regarding an animal population size, and how it changes over time, is a fundamental goal of many ecological studies and monitoring programs. 

Previously, many studies relied on visual detections (e.g. aerial surveys) or signs (e.g. dung counts, snowtracks) to estimate population sizes. These measures were often costly, inefficient, or produced only rough estimates. Other methods, such as capture-recapture analyses, have strict data requirements (e.g. individual recognition) in order to obtain their products.

Camera trapping is a (relatively) new technique that provides a viable alternative approach of sampling from a population. Camera traps can be left out in the field for months at a time, collecting quantitative information 24 hours per day in an automated manner. Cameras also have the advantage of relatively low labour costs, and capital costs are decreasing as the technology improves and becomes more widespread (references *Burton et al 2015*, *Steenweg et al, 2017*).

For species with marked populations, capture-recapture techniques have been combined with camera trapping to provide effective estimates of animal population size (*Karanth and Nichols, 1998*) or density (spatial explicit capture-recapture, *Borchers et al, 2014*). However, the requirement for individual recognition is an exclusionary property in many study contexts. *Chandler and Royle (2013)* propose a method to make use of spatial dependence in observations without the need for individual recognition to make inferences about individual distribution and density.

---

# Model Framework

(simple explanation ie introduction from Dave's paper)

Density is the number of objects (trees, animals, etc.) per unit area. If a 100-m$^2$ plot contains one tree, the density is 1 tree/100-m$^2$, or 10,000 trees per km$^2$. Similarly, if a camera has a field-of-view of 100-m$^2$ and there is always one animal in the field-of-view for the whole time that the camera is operating, the density of that species is 1 animal per 100-m$^2$, or 10,000 animals per km$^2$. It doesn’t matter if the animal is moving around within the field-of-view, as long as it stays in the field-of-view for the whole time. On the other hand, if that camera only has an animal in the field-of-view 1/10,000 of the time that it is operating, there is 1/10,000 animal per 100-m$^2$, or 1 animal per km-$^2$.  If the camera has two animals together for 1/10,000 of the time, this gives 2/10,000 animals per 100-m$^2$, or 2 animals per km-$^2$. 

$$Density = \frac{\sum(number~of~individuals~*~time~in~field~of~view)}{area~of~field~of~view~*~total~camera~operating~time}$$
The units are animal-seconds per area-seconds, which equates to animals per area (i.e. density). For a given density of animals, this simple measure is independent of home range sizes or movement rates. If home ranges were twice as big, they would have to overlap twice as much to maintain the same density. Therefore, an individual would be in a particular camera’s field-of-view half as often (because its home range is bigger – it has more other places to be), but there would be twice as many individuals at that camera. If movement rates were twice as fast, an individual would pass by the camera twice as often, but would spend half as much time in the field-of-view (because it is moving faster).

*Nakashima et al (2019)* were first to describe how density of an animal can be derived from the number of encounters with the camera and the staying time within the camera field of view (i.e. detection zone), and we apply their method ('REST') here. However, we introduce two modifications:

1. Unlike the cameras used by *Nakashima et al (2019)*, images are collected by the ABMI field program rather than video clips. We describe a procedure to convert images taken at discrete intervals to records to a continuous measure, which is required in order to accurately measure the staying time in front of the camera, accounting for uncertainty in animal presence between images.

1. Several studies have pointed out the importance of proper estimating the detection zone in front of the camera (*Rowcliffe et al 2008*; *Rowcliffe et al 2011*; *Hofmeester et al 2017*). 

---

# Application

## Field Data

Description and basic summary statistics of the ABMI's camera monitoring program, to date (2013-2018; hopefully 2019 soon).

- Spatial coverage (maps of deployment locations)
- Species coverage (number of images taken, by species)

## Calculating Total Time in Camera Field of View

Breakdown of how we calculate the individual components of the density formula above.

### Probabilistic Gaps

The camera models used by the ABMI (Reconyx) take a series of images at discrete intervals, rather than providing a continuous record of how long an animal is in the field-of-view (like, for example, the video-recording functions used by *Nakashima et al 2019*). These images need to be converted to a continuous record measure to show how long the animal was in the field-of-view, accounting for the possibility that a moderately long interval between images might be from an animal present, but not moving enough to trigger the camera, versus an animal that left the field-of-view and returned. From a pilot study, we determined that if there is a gap of less than 20 seconds between images of the same species at a camera, the animal is almost always still in the view (no evidence of it walking out and returning). Missing the odd time when it leaves the view for less than 20 seconds has little effect on estimates of the total time it is in the field-of-view. At the other end, if there is a gap of >120 seconds between images of the same species, this almost always represented animals leaving and then returning (i.e., the animal is seen walking out of the field-of-view, then walking back in). Gaps of 20-120 seconds are uncertain. These relatively long periods when the animal could be in the field-of-view or not are important when estimating the total durations animals are in the field-of-view, and thus density.

For the 2015 ABMI images, we checked each 20-120 second gap in series’ of native mammals for evidence of the animal leaving and returning. For 2016 and 2017 ABMI images, we checked 20-120 second gaps only for less common species where we had low sample size from 2015. We looked at several images on either side of gaps of 20-120 seconds. In each sequence, the animal was designated as having left the field-of-view during the 20-120 second gap if there was clear evidence of it walking out of the field-of-view and then returning (or a different individual entering the field-of-view). If the animal stayed in one location within the field-of-view, or sequential images showed the animal in disconnected places (as often happens with smaller animals), the animal was assumed to have stayed.

We used this data to develop models of the probability of a species leaving the field-of-view during a 20-120 second gap as a function of the gap duration. Smoothing splines were fit to the probability of leaving as a function of gap length, using a logit-linked binomial model. This was done separately for each species with enough examined gaps.

```{r}

plot1 <- df_gapcheck %>%
  filter(common_name %in% Sp) %>%
  mutate(common_name = fct_infreq(common_name)) %>%
  ggplot(aes(x = diff_time, y = left, color = common_name)) +
  geom_jitter(height = 0.1, size = 1, alpha = 0.4) +
  geom_line(data = mod_gapcheck_sub, aes(x = seconds, y = pred), color = "black", size = 1) +
  facet_wrap(~common_name, nrow = 3) +
  scale_y_continuous(labels = c("Stayed", 0.2, 0.4, 0.6, 0.8, "Left"), breaks = seq(0, 1, 0.2)) +
  scale_x_continuous(breaks = seq(20, 120, by = 20), limits = c(20, 120)) +
  scale_color_brewer(palette = "Dark2") +
  labs(y = "Probability of Having Left", 
       x = "Gap Length (s)", 
       title = "Did the animal leave the camera field of view?",
       subtitle = "Evaluating gaps between images 20 to 120 seconds in length.") +
  theme_light() +
  theme(legend.position = "none",
        strip.text = element_text(color = "black"))

plot1

```

All images of the same species at the same deployment separated by <120 seconds are therefore considered to be part of a 'series', and the species is in the camera field of view from the time the first image is taken to the last. For images with 20-120 second gaps between them (i.e. the majority of data collected in 2016 and beyond), the above models of gap-leaving probabilities are used to prorate the gaps based on the estimated probability that the animal left. Instead of the full 20-120 second gap length, we only add the duration of the gap x (1 – probability of leaving) to the total series length (illustrated in the figure below, bottom). For example, if there were 4 images separated by 10 seconds, 5 seconds, 60 seconds and 10 seconds, and the model for that species showed a 40% chance that it left in a gap of 60 seconds, then the total time in the field-of-view for that series is 10 + 5 + 60 x (1 - 0.4) + 10 = 61 seconds.

We also consider the time before the first image and after the last image of a series. An animal will generally appear in the field of view slightly before the camera is triggered to take the first image, and remain in the field of view slightly longer after the last image is taken. We estimate that by calculating the average time between images in all series, separately by species. This is typically 4-7 seconds for larger species and somewhat longer for small species. This time is added to the duration of each series, including to single-image series, which would otherwise have a duration of 0 seconds (striped sections in the figure). The assumption is that the animal is in the field-of-view for half the average inter-photo time before the first image, and after the last image.

```{r}

include_graphics(here("./docs/pics/gap_illustration.png"))

```

To calculate the total spent in front of the camera for each series we add all the time up (accounting for probable gaps), then add time before the first photo and after the last. For single image series, this becomes the entire length of time. Finally, we account for the number of individuals in the series. The number of individuals of each species present in each image are counted, and the estimated time in the camera field of view scaled up accordingly. Because the density measure only requires total animal-seconds (i.e. it does not matter which individual(s) is/are in front of the camera at any one time) we simply take the average number of individuals in each images in the series. A series with 1, 1, 2 and 1 individual in its four photos would have 1.25 individuals present on average.  

## Effective Detection Distances of Cameras

Unlike quadrats, cameras do not survey fixed areas, and the probability of an animal triggering the camera decreases with distance. To calculate density via the REST (or REM) method, the sampling area of the camera must be defined. However, this area may differ depending on the species, habitat type (e.g. surrounding vegetation, degree of 'openness'), and season, and not accounting for this heterogeneity may bias downstream density estimates (*Foster and Harmsen, 2012*). One option is to use a fixed maximum distance that defines a focal area in which certain detection can be assumed. This was the approach taken by *Nakashima et al 2019*, who defined their focal with control trials involving a domestic cat in a laboratory setting. Animals that triggered the camera, but were outside this focal area, were not counted in the density estimation. The downside of this approach is that it excludes potentially valuable data from animals detected outside this focal area, in areas that are partially detectable. 

Another approach, first proposed by *Rowcliffe et al 2011*, is to estimate the **effective detection distance** (EDD) of cameras, which is the fixed distance that would give the same number of detections as observed if all animals up to that distance were perfectly detectable and none were detectable further away. Put another way, the EDD is the distance at which the number of animals detected further away equals the number of animals missed nearer by (*Hofmeester et al 2017*). Pioneering this approach, *Rowcliffe et al 2011* developed detection distance models by tracking the movement path of animals through the camera field-of-view, and measuring the distance and angle from the camera at first detection. *Caravaggi et al 2016* reduced the field time required through the use of a photograph of a grid of markers taken after each camera deployment and used image processing software to estimate detection distance and angle. More recently, *Hofmeester et al 2017* simplified the approach even further by establishing physical markers at known distances along the midline of the camera field-of-view, recorded the frequency of animal position in reference to the markers, and used this data to develop models of EDD. 

Similar to *Hofmeester et al 2017*, we take the second approach and place a physical marker in the camera field-of-view to demarcate distance bands. At each deployment, a prominently-colored pole was placed 5-m away from the camera along the mid-line of the field-of-view. We fit detection-distance models using data on position relative to the 5-m pole from all unlured sites in 2015, with supplemental data collected for rarer species and habitats in subsequent years. Ideally, as *Hofmeester et al 2017* recommend, more detailed distance information would be collected (e.g. a greater number of distance bands marked in the field); however, due to field-logistical constraints only two distance bands were defined.

These models are used to estimate the EDD for each species at each camera, based on the species, the habitat type the camera is placed in, and the dates the camera was operating. This calculation is done for all species at all cameras, because it is essential to determine the total area being surveyed by each camera for each species. We can estimate the EDD from the proportion of locations that are <5-m away versus >5-m (ambiguous and investigating images were excluded):

$$EDD~(m) = \frac{5}{sqrt(1-p_{>5m})}$$

where *p* is the proportion of images with the species >5-m away. The area surveyed by a camera can therefore be estimated by:

The area surveyed by a camera is:

$$Surveyed~Area~(m^2)~=~\frac{(π~*~EDD^2~*~angle)}{360}$$ 

where *angle* is the angle of the camera’s field-of-view in degrees (42° for the Reconyx cameras used in this study).

Models were developed for eleven species groups and eight broad habitat types: deciduous forest, upland conifer forest, upland grass, shrub, lowland forest, wet grass, water, and human footprint. BIC-based model selection examined seven models with those habitat types grouped into broader categories, and seven more that added a factor for season (winter = October 15 - April 14, summer = April 15 - October 14). Estimated EDD for four species are displayed below, varying by season and habitat type. 

```{r}

df_edd_final <- read_csv(paste0(mbhd, "processed/detection_distance/predictions/edd_species_site_season_prelim.csv"))

distgroup_labels <- as_labeller(c(`BigForestCarnivores` = "Wolves",
                                `BigForestUngulates` = "Moose",
                                `CoyoteFox` = "Coyotes",
                                `WTDeer` = "White-tailed Deer"))

plot2 <- df_edd_final %>%
  filter(!is.na(edd),
         dist_group != "Mule deer") %>%
  select(-DeploymentYear) %>%
  distinct() %>%
  ggplot(aes(x = VegHF, y = edd, fill = Season)) +
  geom_col(position = "dodge") +
  facet_wrap(~ dist_group, nrow = 3, labeller = distgroup_labels) +
  scale_fill_manual(values = c("#de9b71","#81a9ad")) +
  #guides(fill = guide_legend(title.position = "top",
  #                           label.position = "right",
  #                           nrow = 2)) +
  theme_light() +
  labs(x = "",
       y = "",
       title = "Estimated Effective Detection Distance (EDD) by Species, Habitat, and Season.") +
  theme(legend.position = "bottom",
        legend.direction = "horizontal",
        plot.title = element_text(margin = margin(0, 0, 20, 0)), 
        axis.text.x = element_text(angle = 45, hjust = 1),
        panel.grid.minor.y = element_blank(),
        panel.grid.major.x = element_blank(),
        strip.text = element_text(color = "black"))

plot2

```

---

# Results



## Scaling up density estimates

This is where we discuss how to go from deployment-level density -> WMU-level density.

## Expected precision

Here we discuss simulations of precision.

## Comparisons to other methods

Aerial surveys v cameras

## Habitat association modeling

Results of habitat association modeling


---

# Discussion

## Advantages

1. Not computationally intensive, doesn't require individual demarcation. 

## Limitations

1. Poor method for tracking rare species.


---

# References


Literature is this so far: 

- *Nakashima et al (2019)*

Captures staying time as video; for those researchers who use cameras without video, we describe a procedure to turn series of images taken at discrete intervals into a proxy for a continuous record.  

- *Rowcliffe et al (2008)* - REM

The Random Encounter Model (REM) provides a means to estimate abundance from camera trap rate, but requires camera sensitivity to be quantified.

Studies using these methods rely on camera placements at random positions, which ensures random movement of animals relative to the camera position.

No individual recognition required. Need to account for imperfect detection. 

- *Rowcliffe et al (2011)* - Defines the area in which the number of detections is maximized. 

In this paper a method for estimating species- and survey-specific dimensions of the camera trap detection zone. Detection probability is a function of animal position relative to the camera. 

- Sollmann et al (2013) - bit of a skeptic. Sounds the alarm for needing EDD. 

- *Hofmeester et al (2017)*

Estimating the effective detection distance of camera traps. Correcting for different capture rates.
Many camera-trapping studies do not correct for differences between habitats, implicitly assuming that sampling efficiency of camera traps is constant across habitats. 
Recommend five distance intervals, at minimum. 

- *Pfeffer et al (2017)* - used REM, with EDD incorporated. Three distance markers. 

What we are doing is piecing together a new approach. 

---


The components are thus:

1. Organize images into series

Develop rule set for what constitutes a 'series', which is a continuous set of images. Images < 120 seconds are considered part of a series. Ideally images >20s and <120s would each be checked for evidence of leaving the field of view, but this is impractical given the large volume of data and limited resources checking. Therefore, we've developed an automated process based on a study of images in 2015, and have developed models for probabilistic gaps that can be applied to big datasets.

```{r}



```


2. Calculate total time spent in front of the camera at each deployment

- rule sets for adding time to each series before the first image and after the last image.
- probabilistic time assignment
- sum the time together

3. Model the effective detection distance of the cameras

- Adjusted for species, habitat type, and season.



Ideas for next time:
- Use WTD
- Plot out the binomial GAM results (not sure how?) - by habitat, season ...
- 

Make sure to cite *Buckland et al 2015* - distance sampling. EDD formula. 

```{r}

# Prepare subset of data for effective detection distance (EDD) modeling

df_distance <- df_native_all %>%
  # Clean up "NA" characters (confusing) - replace with "X"
  mutate(distance = str_replace_all(distance, "NA", "X"),
         distance = str_replace_all(distance, "NA, NA", "X, X"),
         distance = str_replace_all(distance, "NA, NA, NA", "X, X, X")) %>%
  # Make columns of number of individuals at each pole position
  mutate(PoleAt = str_count(distance, "A"),
         PoleBehind = str_count(distance, "B"),
         PoleFront = str_count(distance, "F"),
         PoleIC = str_count(distance, "IC"),
         PoleIP = str_count(distance, "IP"),
         PoleNA = str_count(distance, "X")) %>%
  select(deployment:common_name, sex, age_class, number_individuals, distance:PoleNA) %>%
  filter(!is.na(distance)) %>%
  # Join in lure information
  left_join(df_cam_lure, by = c("deployment", "Year" = "year")) %>%
  # Create variable for Julian date
  mutate(Julian = as.numeric(format(ymd_hms(date_time_taken), "%j"))) %>%
  # Filter out lured deployments - only use unlured for detection distance models.
  filter(Lure == "n")

# Retrieve vegetation and human footprint information for each deployment
df_distance_veghf <- df_veghf_detdist %>%
  select(deployment, year, DeploymentYear, VegForDetectionDistance) %>%
  # Get rid of WetShrub - not used for modeling.
  mutate(VegHF = ifelse(VegForDetectionDistance == "WetShrub", 
                        "Shrub", VegForDetectionDistance)) %>%
  select(-VegForDetectionDistance) %>%
  # Join to distance information.
  right_join(df_distance, by = c("deployment", "year" = "Year")) %>%
  mutate(date_time_taken = ymd_hms(date_time_taken)) %>%
  # Join in EDD species grouping lookup
  left_join(df_dist_groups, by = "common_name") %>%
  # Join alternative VegHF categories to try in the modeling
  left_join(df_veg_lookup, by = "VegHF")

df_edd_train <- df_distance_veghf %>%
  # Sum total individuals in each of PoleAt through PoleIP
  mutate(n = rowSums(select(., PoleAt:PoleNA))) %>%
  filter(!is.na(VegHF)) %>%
  # Only use records where number_individuals = PoleBehind or PoleFront
  filter(n == PoleBehind | n == PoleFront) %>%
  # Create season variable based on julian day
  mutate(Season = as.factor(ifelse(Julian >= summer.start.j & Julian <= summer.end.j, "Summer", "Winter")),
         pBehind = PoleBehind / n) %>%
  select(deployment, year, VegHF, VegHF1:VegHF5, common_name, dist_group, n, pBehind, Season)

mod_edd <- df_edd_train %>%
  # Get rid of Pronghorn and Bighorn Sheep - too few obs (for now)
  filter(dist_group != "Pronghorn",
         dist_group != "Bighorn sheep") %>%
  group_by(dist_group) %>%
  nest() %>%
  # Various EDD models w/ vegHF groupings and season
  mutate(
    # Null model
    m1 = map(.x = data, .f = ~ gam(formula = pBehind ~ 1, weights = n, data = .x, family = "binomial")),
    # VegHF groupings only models
    m2 = map(.x = data, .f = ~ gam(formula = pBehind ~ VegHF, weights = n, data = .x, family = "binomial")),
    m3 = map(.x = data, .f = ~ gam(formula = pBehind ~ VegHF1, weights = n, data = .x, family = "binomial")),
    m4 = map(.x = data, .f = ~ gam(formula = pBehind ~ VegHF2, weights = n, data = .x, family = "binomial")),
    m5 = map(.x = data, .f = ~ gam(formula = pBehind ~ VegHF3, weights = n, data = .x, family = "binomial")),
    m6 = map(.x = data, .f = ~ gam(formula = pBehind ~ VegHF4, weights = n, data = .x, family = "binomial")),
    m7 = map(.x = data, .f = ~ gam(formula = pBehind ~ VegHF5, weights = n, data = .x, family = "binomial")),
    # Season only model
    m8 = map(.x = data, .f = ~ gam(formula = pBehind ~ Season, weights = n, data = .x, family = "binomial")),
    # Season + VegHF groupings
    m9 = map(.x = data, .f = ~ gam(formula = pBehind ~ VegHF + Season, 
                                   weights = n, data = .x, family = "binomial")),
    m10 = map(.x = data, .f = ~ gam(formula = pBehind ~ VegHF1 + Season, 
                                    weights = n, data = .x, family = "binomial")),
    m11 = map(.x = data, .f = ~ gam(formula = pBehind ~ VegHF2 + Season, 
                                    weights = n, data = .x, family = "binomial")),
    m12 = map(.x = data, .f = ~ gam(formula = pBehind ~ VegHF3 + Season, 
                                    weights = n, data = .x, family = "binomial")),
    m13 = map(.x = data, .f = ~ gam(formula = pBehind ~ VegHF4 + Season, 
                                    weights = n, data = .x, family = "binomial")),
    m14 = map(.x = data, .f = ~ gam(formula = pBehind ~ VegHF5 + Season, 
                                    weights = n, data = .x, family = "binomial")))

# Calculate BIC to determine weightings for each model
df_edd_bic <- mod_edd %>%
  # Calculate BIC for each species distance group
  mutate(bic.ta = pmap(list(m1,m2,m3,m4,m5,m6,m7,m8,m9,m10,m11,m12,m13,m14), .f = BIC)) %>%
  select(dist_group, data, bic.ta) %>%
  mutate(bic.delta = map(.x = bic.ta, .f = ~ .$BIC - min(.$BIC))) %>%
  mutate(bic.exp = map(.x = bic.delta, .f = ~ exp((-1/2) * .x))) %>%
  mutate(bic.wt = map(.x = bic.exp, .f = ~ .x / sum(.x))) %>%
  mutate(best_model = map_dbl(.x = bic.wt, .f = ~ which.max(.x))) %>%
  select(dist_group, bic.wt, best_model)

# Data to use to make predictions - all deployments w/ all VegHF, season, and distance group combinations. 
df_edd_test <- df_veghf_detdist %>%
  # WetShrub not used in modeling.
  mutate(VegHF = ifelse(VegForDetectionDistance == "WetShrub", "Shrub", VegForDetectionDistance)) %>%
  left_join(df_veg_lookup, by = "VegHF") %>%
  select(DeploymentYear, VegHF, VegHF1:VegHF5) %>%
  # Include both summer and winter options for each deployment
  crossing(Season = c("Summer", "Winter")) %>%
  # Expand each deployment record for each distance group
  crossing(dist_group = mod_edd$dist_group) %>%
  # Nest the data by distance group
  group_nest(dist_group, .key = "pred_data")

# Species group with full set of VegHF categories - still under development here. 
SpGroups <- c("WTDeer", "CoyoteFox", "Mule deer", 
              "BigForestCarnivores", "BigForestUngulates")

# Run predictions, store in list column
df_edd_pred <- df_edd_test %>%
  # Join in models
  left_join(mod_edd, by = "dist_group") %>%
  # Only distance groups with all VegHF categories 
  filter(dist_group %in% SpGroups) %>%
  # Create predictions
  mutate(pred1 = map2(m1, pred_data, .f = ~ predict(.x, newdata = .y)),
         pred2 = map2(m2, pred_data, .f = ~ predict(.x, newdata = .y)),
         pred3 = map2(m3, pred_data, .f = ~ predict(.x, newdata = .y)),
         pred4 = map2(m4, pred_data, .f = ~ predict(.x, newdata = .y)),
         pred5 = map2(m5, pred_data, .f = ~ predict(.x, newdata = .y)),
         pred6 = map2(m6, pred_data, .f = ~ predict(.x, newdata = .y)),
         pred7 = map2(m7, pred_data, .f = ~ predict(.x, newdata = .y)),
         pred8 = map2(m8, pred_data, .f = ~ predict(.x, newdata = .y)),
         pred9 = map2(m9, pred_data, .f = ~ predict(.x, newdata = .y)),
         pred10 = map2(m10, pred_data, .f = ~ predict(.x, newdata = .y)),
         pred11 = map2(m11, pred_data, .f = ~ predict(.x, newdata = .y)),
         pred12 = map2(m12, pred_data, .f = ~ predict(.x, newdata = .y)),
         pred13 = map2(m13, pred_data, .f = ~ predict(.x, newdata = .y)),
         pred14 = map2(m14, pred_data, .f = ~ predict(.x, newdata = .y))) %>%
  select(dist_group, pred1:pred14) %>%
  pivot_longer(cols = pred1:pred14, names_to = "model", values_to = "predictions") %>%
  arrange(dist_group)

# Add BIC information, create adjusted predictions with BIC weighting, and calculate EDD
df_edd_pred_adj <- df_edd_bic %>%
  unnest(bic.wt) %>%
  filter(dist_group %in% SpGroups) %>%
  arrange(dist_group) %>%
  bind_cols(df_edd_pred) %>%
  # Predictions adjusted by BIC weighting
  mutate(predictions_adj = map2(.x = bic.wt, .y = predictions, .f = ~ .x * .y)) %>%
  select(dist_group, predictions_adj) %>%
  unnest_wider(predictions_adj) %>%
  group_by(dist_group) %>%
  summarise_all(funs(sum)) %>%
  pivot_longer(cols = c(-dist_group)) %>%
  mutate(value1 = plogis(value))
  # Calculate EDD
  mutate(edd = 5 / sqrt(1 - plogis(value)))

```

```{r}

df_edd_train_wtd <- df_edd_train %>%
  filter(dist_group == "WTDeer") %>%
  mutate(VegHF_0 = as.factor(VegHF))

# Build WTD model
mod1 <- gam(formula = pBehind ~ VegHF_0, weights = n, data = df_edd_train_wtd, family = "binomial")

summary(mod1)

plot(mod1, all.terms = T, residuals = T)
test <-confint(mod1)

ggplot(data = )

broom::tidy(mod1, parametric = T, conf.int = T, conf.level = 0.9)

```

4. Calculate the total camera operating time


5. Calculate density.

Viola! Looks at some plots for the six species of interest?

---

# Field Data

Introduction to ABMI's data collection efforts to date, including high level details about sampling design.

- The ABMI samples along a grid of the province. At each site, four cameras are placed randomly. 

We're going to focus on ... moose, white-tailed deer, black bears, coyotes, lynx, snowshoe hare. This was discretionary. Do folks have a different preference here?

Maps, plots, tables:
- Detections, occurrences
- Model for probabilistic gaps

---

# Results

```{r}


```


--

# Comparison to other measures of density

- Aerial surveys (WMU moose, Elk Island?)
- Lynx
- Bunny stuff

```{r}

library(abmi.camera.extras)

```

--

# Expected precision of density estimates

Monte Carlo simulations 

```{r}



```

---

# Habitat Association Modeling


Various modeling that can be done - hope to get more recent data soon.

```{r}



```

# References
+ *Kays et al, 2020*









