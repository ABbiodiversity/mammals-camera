---
title: "Monitoring the mammalian community in Alberta's boreal region with remote cameras"
subtitle: "Application of the REST model to large-scale biodiversity monitoring"
author: "Huggard et al."
date: "March 23, 2020"
output:
  word_document: default
  html_document: default
---

```{r setup, include=FALSE}

knitr::opts_chunk$set(include=TRUE, echo=FALSE, message=FALSE, warning=FALSE, eval=TRUE, cache=FALSE)

```

# Outline

1. The Alberta Biodiversity Monitoring Institute (ABMI) monitors mammal populations across the province of Alberta using remote camera traps in order to report on abundance, habitat associations, and trend. From 2013-2019, a total of 2,500 cameras were deployed in a systematic random sampling design, yielding nearly 700,000 images of 42 species of native mammals.

2. We use a modified version of the random encounter and staying time (REST) model developed by *Nakashima et al 2019*, which in turn was an extension of the random encounter model (REM) first proposed by *Rowcliffe et al 2008*. The REST model is used to estimate density based on the total time that a species spends in the camera's field of view (or, more specifically, 'detection zone'), and does not require information on home range size and movement rates. The model also does not require individual recognition. We modify the model developed by *Nakashima et al 2019* by including a procedure to estimate animal staying time from series of images taken at discrete intervals (rather than video), and the development of species, habitat, and seasonally varying models of the effective detection distance (EDD) of cameras. This latter component was developed using image data collected from a full field season (2015), rather than a laboratory. We discuss important assumtions of using this model to estimate the absolute density of a species, including the necessity that cameras survey a random (or representative) sample of the larger region and that animals are not attracted to or repelled by the cameras.

3. We report density estimates based on data collected from 2,500 cameras deployed throughout the province from 2013 to 2019 for six small- to large-size mammal species of interest (which range from relatively common to relatively rare): white-tailed deer, moose, black bear, coyote, snowshoe hare, and gray wolf. We scale up these density estimates to the Wildlife Management Unit (WMU; an important spatial unit for wildlife management in the province) and use Monte Carlo simulation to estimate confidence bounds. The expected precision of these estimates, and the ensuing implications for management, differ greatly depending on the number of cameras and the relative prevalence of the species of interest. We use additional Monte Carlo simulation to illustrate how expected precision changes with sampling effort for the focal species listed above.

4. Since 2014, aerial surveys using distance sampling methods have been used to monitor ungulate populations at the WMU level in Alberta. We compare density estimates of moose obtained from the REST model to those reported via aerial surveys, and find a significantly positive relationship. Estimates from the REST model were approximately 2-3 times higher than than their equivalent aerial estimate, highlighting a likely violation of model assumptions (e.g. moose not being attracted to the camera). However, we suggest density derived via REST can be useful as a metric of *relative* density, provided that assumptions are violated equally over time and space. We propose a preliminary approach to scale REST estimates to their aerial equivalent.

5. Finally, we outline how relative density estimates derived via REST at camera deployments can be used to form inference on the habitat preferences of species. We use a joint presence-absence/abundance-given-presence approach to model moose habitat associations in the boreal region of Alberta.

## Key Features 

- Application of the random encounter staying time (REST) model by a multi-species biodiversity monitoring program with large temporal and spatial breadth.
  + Includes proposed modifications to the original REST model in order to handle images taken at discrete intervals and methods to account for variation in effective detection distance (EDD) by species, habitat, and season. 
  
- Comparison to other, well-developed large-scale methods for animal population monitoring, i.e. aerial surveys.

- Use of REST-derived density estimates at individual camera deployment sampling points to study habitat preference.
  
```{r}

# Load packages
library(dplyr) # data manipulation
library(readr) # read in csv data
library(mgcv) # gam modeling
library(stringr)
library(knitr)
library(tidyr)
library(lubridate) # dates
library(forcats) # factors
library(ggplot2) # visualizations
library(here)

# Path to data folder on ABMI Science Centre S: drive
abmisc <- "S:/github-repos-data/SC-Camera-Mammals/data/"
# Path to data folder on MB's external hardrive 
mbhd <- "D:/SC-Camera-Mammals/data/"

# Import data
df_gapcheck <- read_csv(paste0(mbhd, "processed/probabilistic-gaps/gap-check.csv"))
mod_gapcheck_sub <- read_csv(paste0(mbhd, "processed/probabilistic-gaps/gap-mod.csv"))
df_edd_final <- read_csv(paste0(mbhd, "processed/detection_distance/predictions/edd_species_site_season_prelim.csv"))
df_density <- read_csv(paste0(mbhd, "processed/density/density-by-season-deployment-species.csv"))
df_comp <- read_csv(paste0(mbhd, "supplemental/aerial-camera-combined_2014-19.csv")) %>%
  mutate(wt1 = sqrt(Camera.n))

# Example species
Sp <- c("White-tailed Deer", "Moose", "Black Bear", "Coyote", "Snowshoe Hare", "Gray Wolf")

```


---

# Introduction

(broad discussion of the literature to-date.)

Accurate and reliable information regarding an animal population size, and how it changes over time, is a fundamental goal of many ecological studies and monitoring programs. 

Previously, many studies relied on visual detections (e.g. aerial surveys) or signs (e.g. dung counts, snowtracks) to estimate population sizes. These measures were often costly, inefficient, or produced only rough estimates. Other methods, such as capture-recapture analyses, have strict data requirements (e.g. individual recognition) in order to obtain their products.

Camera trapping is an emerging research technique that provides a viable alternative approach of sampling from a population. Camera traps can be left out in the field for months at a time, collecting quantitative information 24 hours per day in an automated manner. Cameras also have the advantage of relatively low labour costs, and capital costs are decreasing as the technology improves and becomes more widespread (references *Burton et al 2015*, *Steenweg et al, 2017*).

For species with marked populations, capture-recapture techniques have been combined with camera trapping to provide effective estimates of animal population size (*Karanth and Nichols, 1998*) or density (spatially explicit capture-recapture, *Borchers et al, 2014*). However, the requirement for individual recognition can be inhibitive in many monitoring and study designs. *Chandler and Royle (2013)* proposed a method to make use of spatial dependence in observations without the need for individual recognition to make inferences about individual distribution and density.

Another framework was proposed *Rowcliffe et al 2008*, which they deemed the Random Encounter Model (REM). The REM posits that the camera trapping rate (number of contacts between camera traps and animals during a unit of time) is function of animal movement speed, animal density, and the area that camera traps are able to successfully detect animals. Using field data, *Rowcliffe et al 2008* provide field evidence that the REM performed well in the density estimation of three of four ungulate species. Subsequent research has focused on methods to estimate the required parameters of this model: the area of camera detection (e.g. *Rowcliffe et al 2011*, *Caravaggi et al 2016*) and the animal movement speed (or daily travel distance) (*Rowcliffe et al 2016*).

Given the difficulty in adequatly measuring animal movement speeds, *Nakashima et al 2019* proposed an alternative, but closely related, approach to estimating density using an animals' staying time in the camera field of view (REST). Similar to the REM, their approach to density estimation relies on the random encounter of animals within a prescribed zone of camera detection. However, they describe how the staying time in front of the camera is inversely proportional to movement speeds and can thus be substituted as a model parameter. Given the improvement in camera technology, observation of animal behaviour and thus measurment of staying time is becoming easier.

In this paper we describe the use of the REST model on camera trap data collected by a long-term large-scale biodiversity monitoring program. We propose several modifications to the REST model, and report on how sampling effort influences expected precision of density estimates for various mammal species of the province. We also compare density estimates derived via the REST approach to more traditional methods such as aerial surveys.

---

# Model Framework

(simple explanation, i.e. introduction from Dave's paper)

Density is the number of objects (trees, animals, etc.) per unit area. If a 100-m$^2$ plot contains one tree, the density is 1 tree/100-m$^2$, or 10,000 trees per km$^2$. Similarly, if a camera has a field-of-view of 100-m$^2$ and there is always one animal in the field-of-view for the whole time that the camera is operating, the density of that species is 1 animal per 100-m$^2$, or 10,000 animals per km$^2$. It doesn’t matter if the animal is moving around within the field-of-view, as long as it stays in the field-of-view for the whole time. On the other hand, if that camera only has an animal in the field-of-view 1/10,000 of the time that it is operating, there is 1/10,000 animal per 100-m$^2$, or 1 animal per km-$^2$.  If the camera has two animals together for 1/10,000 of the time, this gives 2/10,000 animals per 100-m$^2$, or 2 animals per km-$^2$. 

$$Density = \frac{\sum(number~of~individuals~*~time~in~field~of~view)}{area~of~field~of~view~*~total~camera~operating~time}$$
The units are animal-seconds per area-seconds, which equates to animals per area (i.e. density). For a given density of animals, this simple measure is independent of home range sizes or movement rates. If home ranges were twice as big, they would have to overlap twice as much to maintain the same density. Therefore, an individual would be in a particular camera’s field-of-view half as often (because its home range is bigger – it has more other places to be), but there would be twice as many individuals at that camera. If movement rates were twice as fast, an individual would pass by the camera twice as often, but would spend half as much time in the field-of-view (because it is moving faster).

*Nakashima et al (2019)* were first to describe how density of an animal can be derived from the number of encounters with the camera and the staying time within the camera field of view (i.e. detection zone), and we apply their method ('REST') here. However, we introduce two modifications:

1. Unlike the cameras used by *Nakashima et al (2019)*, images are collected rather than video clips. We describe a procedure to convert images taken at discrete intervals to records to a continuous measure, which is required in order to measure the staying time in front of the camera, accounting for uncertainty in animal presence between images.

1. Several studies have highlighted the importance of properly estimating the detection zone in front of the camera (*Rowcliffe et al 2008*; *Rowcliffe et al 2011*; *Hofmeester et al 2017*). Following the procedure proposed in *Hofmeester et al 2017*, we place a pole 5-m away from the camera and record whether the animal captured in the image is in front of or behind the pole. This data is used to develop models of the effective detection distance of the camera, which varies by species, habitat type, and season. 

In order to use this model to give absolute density of a species, the following assumptions are made:

1. In order to make inferences about density over a larger region, the cameras must form a random or otherwise representative sample.

1. Animals are not attracted to or repelled by the cameras, and they do not change their behaviour (i.e. time spent in front of the camera) because of the cameras.

1. The method to estimate detection distances in different habitats assumes that the animal is certain to be detected within the 5-m band.

The practical implications of these assumptions, and their potential violation, are discussed throughout and in the Discussion section at the end of paper. 

---

# Application

## Field Data

Description and basic summary statistics of the ABMI's camera monitoring program, to date (2013-2018; hopefully 2019 soon).

- Spatial coverage (maps of deployment locations)
- Species coverage (number of images taken, by species)

## Calculating Total Time in Camera Field of View

Breakdown of how we calculate the individual components of the density formula above.

### Probabilistic Gaps

The camera models used by the ABMI (Reconyx) take a series of images at discrete intervals, rather than providing a continuous record of how long an animal is in the field-of-view (like, for example, the video-recording functions used by *Nakashima et al 2019*). These images need to be converted to a continuous record measure to show how long the animal was in the field-of-view, accounting for the possibility that a moderately long interval between images might be from an animal present, but not moving enough to trigger the camera, versus an animal that left the field-of-view and returned. From a pilot study, we determined that if there is a gap of less than 20 seconds between images of the same species at a camera, the animal is almost always still in the view (no evidence of it walking out and returning). Missing the odd time when it leaves the view for less than 20 seconds has little effect on estimates of the total time it is in the field-of-view. At the other end, if there is a gap of >120 seconds between images of the same species, this almost always represented animals leaving and then returning (i.e., the animal is seen walking out of the field-of-view, then walking back in). Gaps of 20-120 seconds are uncertain. These relatively long periods when the animal could be in the field-of-view or not are important when estimating the total durations animals are in the field-of-view, and thus density.

For the 2015 ABMI images, we checked each 20-120 second gap in series’ of native mammals for evidence of the animal leaving and returning. For 2016 and 2017 ABMI images, we checked 20-120 second gaps only for less common species where we had low sample size from 2015. We looked at several images on either side of gaps of 20-120 seconds. In each sequence, the animal was designated as having left the field-of-view during the 20-120 second gap if there was clear evidence of it walking out of the field-of-view and then returning (or a different individual entering the field-of-view). If the animal stayed in one location within the field-of-view, or sequential images showed the animal in disconnected places (as often happens with smaller animals), the animal was assumed to have stayed.

We used this data to develop models of the probability of a species leaving the field-of-view during a 20-120 second gap as a function of the gap duration. Smoothing splines were fit to the probability of leaving as a function of gap length, using a logit-linked binomial model. This was done separately for each species with enough examined gaps.

```{r}

plot1 <- df_gapcheck %>%
  filter(common_name %in% Sp) %>%
  # mutate(common_name = fct_infreq(common_name)) %>%
  ggplot(aes(x = diff_time, y = left, color = common_name)) +
  geom_jitter(height = 0.1, size = 1, alpha = 0.4) +
  geom_line(data = (mod_gapcheck_sub %>% filter(common_name %in% Sp)),
            aes(x = seconds, y = pred), color = "black", size = 1) +
  facet_wrap(~common_name, nrow = 2) +
  scale_y_continuous(labels = c("Stayed", 0.2, 0.4, 0.6, 0.8, "Left"), breaks = seq(0, 1, 0.2)) +
  scale_x_continuous(breaks = seq(20, 120, by = 20), limits = c(20, 120)) +
  scale_color_viridis_d() +
  labs(y = "Probability of Having Left", 
       x = "Gap Length (s)", 
       title = "Did the animal leave the camera field of view?",
       subtitle = "Evaluating gaps between images 20 to 120 seconds in length.") +
  theme_light() +
  theme(legend.position = "none",
        strip.text = element_text(color = "black"))

include_graphics(here("./docs/pics/plot1.png"))

```

All images of the same species at the same deployment separated by <120 seconds are therefore considered to be part of a 'series', and the species is in the camera field of view from the time the first image is taken to the last. For images with 20-120 second gaps between them (i.e. the majority of data collected in 2016 and beyond), the above models of gap-leaving probabilities are used to prorate the gaps based on the estimated probability that the animal left. Instead of the full 20-120 second gap length, we only add the duration of the gap x (1 – probability of leaving) to the total series length (illustrated in the figure below, bottom). For example, if there were 4 images separated by 10 seconds, 5 seconds, 60 seconds and 10 seconds, and the model for that species showed a 40% chance that it left in a gap of 60 seconds, then the total time in the field-of-view for that series is 10 + 5 + 60 x (1 - 0.4) + 10 = 61 seconds.

We also consider the time before the first image and after the last image of a series. An animal will generally appear in the field of view slightly before the camera is triggered to take the first image, and remain in the field of view slightly longer after the last image is taken. We estimate that by calculating the average time between images in all series, separately by species. This is typically 4-7 seconds for larger species and somewhat longer for small species. This time is added to the duration of each series, including to single-image series, which would otherwise have a duration of 0 seconds (striped sections in the figure). The assumption is that the animal is in the field-of-view for half the average inter-photo time before the first image, and after the last image.

```{r}

include_graphics(here("./docs/pics/gap_illustration.png"))

```

To calculate the total spent in front of the camera for each series we add all the time up (accounting for probable gaps), then add time before the first photo and after the last. For single image series, this becomes the entire length of time. Finally, we account for the number of individuals in the series. The number of individuals of each species present in each image are counted, and the estimated time in the camera field of view scaled up accordingly. Because the density measure only requires total animal-seconds (i.e. it does not matter which individual(s) is/are in front of the camera at any one time) we simply take the average number of individuals in each images in the series. A series with 1, 1, 2 and 1 individual in its four photos would have 1.25 individuals present on average.  

## Effective Detection Distances of Cameras

Unlike quadrats, cameras do not survey fixed areas, and the probability of an animal triggering the camera decreases with distance. To calculate density via the REST (or REM) method, the sampling area of the camera must be defined. However, this area may differ depending on the species, habitat type (e.g. surrounding vegetation, degree of 'openness'), and season, and not accounting for this heterogeneity may bias downstream density estimates (*Foster and Harmsen, 2012*). One option is to use a fixed maximum distance that defines a focal area in which certain detection can be assumed. This was the approach taken by *Nakashima et al 2019*, who defined their focal with control trials involving a domestic cat in a laboratory setting. Animals that triggered the camera, but were outside this focal area, were not counted in the density estimation. The downside of this approach is that it excludes potentially valuable data from animals detected outside this focal area, in areas that are partially detectable. 

Another approach, first proposed by *Rowcliffe et al 2011*, is to estimate the **effective detection distance** (EDD) of cameras, which is the fixed distance that would give the same number of detections as observed if all animals up to that distance were perfectly detectable and none were detectable further away. Put another way, the EDD is the distance at which the number of animals detected further away equals the number of animals missed nearer by (*Hofmeester et al 2017*). Pioneering this approach, *Rowcliffe et al 2011* developed detection distance models by tracking the movement path of animals through the camera field-of-view, and measuring the distance and angle from the camera at first detection. *Caravaggi et al 2016* reduced the field time required through the use of a photograph of a grid of markers taken after each camera deployment and used image processing software to estimate detection distance and angle. More recently, *Hofmeester et al 2017* simplified the approach even further by establishing physical markers at known distances along the midline of the camera field-of-view, recorded the frequency of animal position in reference to the markers, and used this data to develop models of EDD. 

Similar to *Hofmeester et al 2017*, we take the second approach and place a physical marker in the camera field-of-view to demarcate distance bands. At each deployment, a prominently-colored pole was placed 5-m away from the camera along the mid-line of the field-of-view. We fit detection-distance models using data on position relative to the 5-m pole from all unlured sites in 2015, with supplemental data collected for rarer species and habitats in subsequent years. Ideally, as *Hofmeester et al 2017* recommend, more detailed distance information would be collected (e.g. a greater number of distance bands marked in the field); however, due to field-logistical constraints only two distance bands were defined.

These models are used to estimate the EDD for each species at each camera, based on the species, the habitat type the camera is placed in, and the dates the camera was operating. This calculation is done for all species at all cameras, because it is essential to determine the total area being surveyed by each camera for each species. We can estimate the EDD from the proportion of locations that are <5-m away versus >5-m (ambiguous and investigating images were excluded):

$$EDD~(m) = \frac{5}{sqrt(1-p_{>5m})}$$

where *p* is the proportion of images with the species >5-m away. The area surveyed by a camera can therefore be estimated by:

The area surveyed by a camera is:

$$Surveyed~Area~(m^2)~=~\frac{(π~*~EDD^2~*~angle)}{360}$$ 

where *angle* is the angle of the camera’s field-of-view in degrees (42° for the Reconyx cameras used in this study).

Models were developed for eleven species groups and eight broad habitat types: deciduous forest, upland conifer forest, upland grass, shrub, lowland forest, wet grass, water, and human footprint. BIC-based model selection examined seven models with those habitat types grouped into broader categories, and seven more that added a factor for season (winter = October 15 - April 14, summer = April 15 - October 14). Estimated EDD for four species are displayed below, varying by season and habitat type. 

```{r}

distgroup_labels <- as_labeller(c(`BigForestCarnivores` = "Wolves",
                                `BigForestUngulates` = "Moose",
                                `CoyoteFox` = "Coyotes",
                                `WTDeer` = "White-tailed Deer"))

plot2 <- df_edd_final %>%
  filter(!is.na(edd),
         dist_group != "Mule deer") %>%
  select(-DeploymentYear) %>%
  distinct() %>%
  ggplot(aes(x = VegHF, y = edd, fill = Season)) +
  geom_col(position = "dodge", color = "black") +
  facet_wrap(~ dist_group, nrow = 2, labeller = distgroup_labels) +
  scale_fill_manual(values = c("#de9b71","#81a9ad")) +
  scale_y_continuous(limits = c(0, 12), breaks = seq(0, 12, 3)) +
  theme_light() +
  labs(x = "",
       y = "",
       title = "Estimated Effective Detection Distance (EDD) by Species, Habitat,\nand Season (metres).") +
  theme(legend.position = "bottom",
        legend.direction = "horizontal",
        legend.text = element_text(size = 12),
        panel.spacing.x = unit(0.7, "cm"),
        panel.spacing.y = unit(0.3, "cm"),
        plot.title = element_text(margin = margin(0, 0, 15, 0)), 
        axis.text.x = element_text(angle = 45, hjust = 1),
        axis.text.y = element_text(size = 10),
        panel.grid.minor.y = element_blank(),
        panel.grid.major.x = element_blank(),
        strip.text = element_text(color = "black", size = 10),
        legend.box.margin = margin(-10, -10, -10, -10))

include_graphics(here("./docs/pics/plot2.png"))

```

## Total Camera Operating Time

Here we briefly discuss patterns of field deployment and operation time of ABMI cameras. 

---

# Results

We present our deployment-level results of density for the six species of interest, methods to scale up density to an area of interest, expected precision using simulation, and present a simple habitat assoication model as another potential use for the relative density index. 

## Deployment-level density estimates

The distributions of density estimates of species at deployments are extremely skewed, with a large majority of deployments having none of a species, some deployments having low densities (one or a few individuals passing by) while a few have very high values (one or more individuals spending long periods in front of a particular camera).

```{r}

plot3 <- df_density %>%
  filter(common_name %in% Sp,
         str_detect(DeploymentYear, "^ABMI")) %>%
  group_by(DeploymentYear, common_name) %>%
  summarise(density = mean(cpue_km2)) %>%
  #left_join(df_native_top11, by = "common_name") %>%
  #mutate(common_name = fct_reorder(factor(common_name), images, .desc = TRUE)) %>%
  ggplot(mapping = aes(x = density, fill = common_name)) +
    geom_histogram(bins = 40) +
    scale_fill_viridis_d(direction = 1) +
    coord_cartesian(ylim = c(0,250)) +
    #scale_y_log10() +
    labs(x = expression(Density~(individuals~per~km^2)),
         y = "Number of Deployments",
         title = "Distribution in estimated density at ABMI camera deployments for 6\nexample species.") +
    facet_wrap(~ common_name, scales = "free") +
    theme_light() +
    theme(legend.position = "none",
          panel.grid.minor = element_blank(),
          strip.text = element_text(color = "black"))

include_graphics(here("./docs/pics/plot3.png"))
                       

```

## Scaling up density estimates

This is where we discuss how to go from deployment-level density -> WMU-level density.

## Expected precision

(Here we discuss the use of simulations to better understand expected precision from various levels of sampling effort, i.e. number of cameras, time in the field). 

Such distributions require large sample sizes to obtain precise estimates – for example, for yearly changes in density in a region or to use for estimating abundances in different habitat types.

## Comparisons to other methods

Here we compare camera-derived density estimates to another widely-used method to monitor wildlife populations in Alberta: aerial surveys. Aerial surveys are conducted by the Government of Alberta to report on (primarily) ungulate populations, and results are reported at the Wildlife Management Unit (WMU) level. We obtained estimates of moose density for 34 WMUs conducted from 2014-2019 using distance sampling methodology, and compared them to estimates of moose density measured by ABMI cameras using the REST method. 

* Note: we will be able to add 2019 camera data and 2020 aerial survey data soon.

We fit models of camera density as a function of aerial survey density, including GAMs with smoothing splines using both normal and log-normal (log-link) error distributions, and a linear model both with and without an intercept. Points were weighted in inverse proportion to the width of the camera confidence intervals, which vary widely due to large differences in number of cameras per WMU and inherent variability of camera estimates.

```{r}

m.gam1 <- gam(data = df_comp, Camera.mean ~ s(Aerial.mean, k=6, m=2), family = "gaussian", weights = wt1)
x<-seq(0,0.75,0.01)
predmgam1 <- predict(m.gam1, newdata = data.frame(Aerial.mean = x), se.fit = TRUE)
predline1 <- data.frame(x, predmgam1$fit)

plot4 <- df_comp %>%
  ggplot(mapping = aes(x = Aerial.mean, y = Camera.mean)) +
  geom_smooth(method = "lm", se = FALSE, aes(color = "Linear"), size = 2) +
  geom_line(data = predline1, mapping = aes(x = x, y = predmgam1.fit, color = "GAM"),
            size = 2) +
  geom_point(size = 3) +
  theme_light() +
  labs(x = expression(Aerial~Density~(per~km^2)),
       y = expression(Camera~Density~(per~km^2)),
       color = "Model:",
       title = "Comparison of moose density estimates between two monitoring methods.") +
       #subtitle = "Aerial ungulate surveys and remote cameras") + #,
       #caption = "The linear model has an adjusted R-squared value of 0.68") +
  scale_x_continuous(breaks = seq(0,0.8,0.1)) +
  scale_y_continuous(breaks = seq(0,3,0.5)) +
  theme(axis.title = element_text(size = 12),
        axis.text = element_text(size = 10),
        legend.title = element_text(size = 13),
        legend.text = element_text(size = 13),
        legend.position = "bottom",
        plot.title = element_text(size = 14, margin = margin(0, 0, 10, 0)),
        panel.grid.minor = element_blank())

include_graphics(here("./docs/pics/plot4.png"))

```

There is a general positive relationship between camera estimates and aerial-survey estimates of moose across WMU’s, but wide scatter as densities increase. Because the models produced similar results and the linear model without intercept is the simplest for calibration, we use that model. The calibration coefficient, 1/slope of the linear model without intercept, is 0.406 (90% CI’s: 0.341-0.503). That means that the aerial estimate for moose density in a WMU is 0.406 times the camera estimate. Equivalently, the camera estimate is 2.46 times higher than the aerial estimate. 

The substantial overestimation of moose densities by cameras (assuming the aerial densities are close to the true value) is expected. ABMI cameras are put in open micro-habitats so that vegetation doesn’t hide animals for at least 5m; moose prefer those open areas for foraging, particularly in summer. Additionally, moose are clearly attracted to the cameras themselves, often going right up to the camera to investigate it. This inflates densities estimates by increasing the time that moose spend in the camera’s field-of-view and also reducing the effective detection distance that shows what area the camera is surveying.

+ Lynx in the Yukon?

+ Snowshoe hares?

## Habitat association modeling

Results of habitat association modeling

For habitat modeling, we find that the density estimates are best treated as a compound distribution of presence/absence – modeling how the 0 records differ from the non-0 records – and of abundance where the species is present – explaining variation in abundance where the species was recorded. We model presence/absence with the typical logit-linked binomial model, and the abundance-given-presence distribution with a log-normal distribution, which fits most of the species’ distributions reasonably well. This compound distribution is the same as a zero-inflated log-normal distribution, but explicitly treating the two components separately allows more flexible modeling and critical examination of each component.

```{r}

plot5 <- df_density %>%
  filter(common_name %in% Sp,
         str_detect(DeploymentYear, "^ABMI")) %>%
  group_by(DeploymentYear, common_name) %>%
  summarise(density = mean(cpue_km2)) %>%
  #left_join(df_native_top11, by = "common_name") %>%
  #mutate(common_name = fct_reorder(factor(common_name), images, .desc = TRUE)) %>%
  # Filter out deployments with density of 0
  filter(density > 0) %>%
  ggplot(mapping = aes(x = density, fill = common_name)) +
    geom_histogram(bins = 30) +
    scale_fill_viridis_d(direction = -1) +
    scale_x_log10(labels = scales::number_format(accuracy = 0.1)) +
    labs(x = expression(Density~(individuals~per~km^2)),
         y = "Number of Deployments",
         title = "Log-normal distribution of density using only presence records for 6 example\nspecies.") +
    facet_wrap(~ common_name, scales = "free_x") +
    theme_light() +
    theme(legend.position = "blank",
          panel.grid.minor = element_blank(),
          strip.text = element_text(color = "black"))

include_graphics(here("./docs/pics/plot5.png"))

```

Following this up with how we would build a habitat association for, say, Moose.

---

# Discussion

## Advantages

1. Relaxes requirements for recognizing individual demarcation, estimation of movement speed, and home range size.
1. Not computationally intensive.
1. Evidence that the REST method can provide unbiased estimates of animal density. 

## Limitations

1. Poor method for monitoring rare species (and herding species?) as high sampling effort required for precise results.
1. Assumptions may be violated in real-world practice; estimates may then still be useful as a measure of *relative* density. 

---

# References

Borchers, D., Distiller, G., Foster, R., Harmsen, B., & Milazzo, L. (2014). Continuous‐time spatially explicit capture–recapture models, with an application to a jaguar camera‐trap survey. Methods in Ecology and Evolution, 5(7), 656-665 https://doi.org/10.1111/2041-210X.12196.

Burton, A. C., Neilson, E., Moreira, D., Ladle, A., Steenweg, R., Fisher, J. T., ... & Boutin, S. (2015). Wildlife camera trapping: a review and recommendations for linking surveys to ecological processes. Journal of Applied Ecology, 52(3), 675-685. https://doi.org/10.1111/1365-2664.12432.

Chandler, R. B., & Royle, J. A. (2013). Spatially explicit models for inference about density in unmarked or partially marked populations. The Annals of Applied Statistics, 7(2), 936-954. https://doi.org/10.1214/12-AOAS610.

Foster, R. J., & Harmsen, B. J. (2012). A critique of density estimation from camera‐trap data. The Journal of Wildlife Management, 76(2), 224-236. https://doi.org/10.1002/jwmg.275.

Hofmeester, T. R., Rowcliffe, J. M., & Jansen, P. A. (2017). A simple method for estimating the effective detection distance of camera traps. Remote Sensing in Ecology and Conservation, 3(2), 81-89. https://doi.org/10.1002/rse2.25.

Karanth, K. U., & Nichols, J. D. (1998). Estimation of tiger densities in India using photographic captures and recaptures. Ecology, 79(8), 2852-2862. https://doi.org/10.1890/0012-9658(1998)079[2852:EOTDII]2.0.CO;2.

Kays, R., Arbogast, B. S., Baker‐Whatton, M., Beirne, C., Boone, H. M., Bowler, M., ... & Gonçalves, A. L. S. (2020). An empirical evaluation of camera trap study design: how many, how long, and when?. Methods in Ecology and Evolution. https://doi.org/10.1111/2041-210X.13370.

Nakashima, Y., Fukasawa, K., & Samejima, H. (2018). Estimating animal density without individual recognition using information derivable exclusively from camera traps. Journal of Applied Ecology, 55(2), 735-744. https://doi.org/10.1111/1365-2664.13059.

Pfeffer, S. E., Spitzer, R., Allen, A. M., Hofmeester, T. R., Ericsson, G., Widemo, F., ... & Cromsigt, J. P. (2018). Pictures or pellets? Comparing camera trapping and dung counts as methods for estimating population densities of ungulates. Remote Sensing in Ecology and Conservation, 4(2), 173-183. https://doi.org/10.1002/rse2.67.

Rowcliffe, J. M., Field, J., Turvey, S. T., & Carbone, C. (2008). Estimating animal density using camera traps without the need for individual recognition. Journal of Applied Ecology, 45(4), 1228-1236. https://doi.org/10.1111/j.1365-2664.2008.01473.x.

Rowcliffe, J. M., Carbone, C., Jansen, P. A., Kays, R., & Kranstauber, B. (2011). Quantifying the sensitivity of camera traps: an adapted distance sampling approach. Methods in Ecology and Evolution, 2(5), 464-476. https://doi.org/10.1111/j.2041-210X.2011.00094.x.

Sollmann, R., Mohamed, A., Samejima, H., & Wilting, A. (2013). Risky business or simple solution–Relative abundance indices from camera-trapping. Biological Conservation, 159, 405-412. https://doi.org/10.1016/j.biocon.2012.12.025.

Steenweg, R., Hebblewhite, M., Kays, R., Ahumada, J., Fisher, J. T., Burton, C., ... & Brodie, J. (2017). Scaling‐up camera traps: Monitoring the planet's biodiversity with networks of remote sensors. Frontiers in Ecology and the Environment, 15(1), 26-34. https://doi.org/10.1002/fee.1448.










